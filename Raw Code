import cv2
import mediapipe as mp
from mediapipe.python.solutions.drawing_utils import draw_landmarks
import math
from ctypes import cast, POINTER
from comtypes import CLSCTX_ALL
from pycaw.pycaw import AudioUtilities, IAudioEndpointVolume
import numpy as np

# Initialize the audio devices and volume control
devices = AudioUtilities.GetSpeakers()
interface = devices.Activate(IAudioEndpointVolume._iid_, CLSCTX_ALL, None)
volume = cast(interface, POINTER(IAudioEndpointVolume))

# Initialize OpenCV video capture
cap = cv2.VideoCapture(0)

# Initialize MediaPipe Hands
mpHands = mp.solutions.hands
hands = mpHands.Hands()
mpDraw = mp.solutions.drawing_utils

while True:
    # Read frame from the camera
    success, img = cap.read()
    if not success:
        break

    # Convert the image to RGB
    imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    # Process the image to detect hands
    results = hands.process(imgRGB)

    # If hands are detected
    if results.multi_hand_landmarks:
        for handLms in results.multi_hand_landmarks:
            lmList = []
            for id, lm in enumerate(handLms.landmark):
                h, w, c = img.shape
                cx, cy = int(lm.x * w), int(lm.y * h)
                lmList.append([id, cx, cy])

            # Draw landmarks on the image
            mpDraw.draw_landmarks(img, handLms, mpHands.HAND_CONNECTIONS)

            if lmList:
                # Get the positions of the thumb (id 4) and index finger (id 8)
                x1, y1 = lmList[4][1], lmList[4][2]
                x2, y2 = lmList[8][1], lmList[8][2]

                # Draw circles and line between thumb and index finger
                cv2.circle(img, (x1, y1), 15, (255, 0, 0), cv2.FILLED)
                cv2.circle(img, (x2, y2), 15, (255, 0, 0), cv2.FILLED)
                cv2.line(img, (x1, y1), (x2, y2), (255, 0, 255), 3)

                # Calculate the midpoint and length between the two fingers
                z1, z2 = (x1 + x2) // 2, (y1 + y2) // 2
                length = math.hypot(x2 - x1, y2 - y1)

                # If the length is less than 50, draw a white circle at the midpoint
                if length < 50:
                    cv2.circle(img, (z1, z2), 15, (255, 255, 255), cv2.FILLED)

                # Map the length to the volume range
                volRange = volume.GetVolumeRange()
                minVol = volRange[0]
                maxVol = volRange[1]
                vol = np.interp(length, [50, 300], [minVol, maxVol])
                volBar = np.interp(length, [50, 300], [400, 150])
                volPer = np.interp(length, [50, 300], [0, 100])

                # Set the system volume
                volume.SetMasterVolumeLevel(vol, None)

                # Draw the volume bar and percentage on the image
                cv2.rectangle(img, (50, 150), (85, 400), (123, 213, 122), 3)
                cv2.rectangle(img, (50, int(volBar)), (85, 400), (0, 231, 23), cv2.FILLED)
                cv2.putText(img, f"{int(volPer)}%", (40, 450), cv2.FONT_HERSHEY_PLAIN, 4, (24, 34, 34), 3)

    # Display the image
    cv2.imshow("Image", img)

    # Break the loop if 'q' is pressed
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# Release the video capture and close all OpenCV windows
cap.release()
cv2.destroyAllWindows()
